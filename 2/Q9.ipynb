{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Param-Bhatt/NNFL-Assignment/blob/master/2/Q9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w_EOK59DWYe"
      },
      "source": [
        "<h3> Ignore warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBtkmAIPXhZI"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqbWXigpDoRV"
      },
      "source": [
        "<h3> Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uorl16JDlpi",
        "outputId": "a6ccd339-20b1-44b8-88d5-8831b6d459e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3hsafZ8Decx"
      },
      "source": [
        "<h3>Navigating to respective directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVZ-Q3vCRlrm",
        "outputId": "86fde94e-d467-451a-e449-054077195b8f"
      },
      "source": [
        "%cd \"/content/drive/My Drive/NNFL-Assignments/2\"\n",
        "!ls"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NNFL-Assignments/2\n",
            "assignment2.gdoc  class2_images    class_label.mat  data5.mat\t  input.mat\n",
            "assignment2.pdf   class3_images    data55.xlsx\t    input_a2.mat  label.mat\n",
            "class1_images\t  class_label.csv  data5.csv\t    input.gsheet  Q8.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SENcBj6nDjTf"
      },
      "source": [
        "<h3>Importing all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TxzwiNQZrh"
      },
      "source": [
        "import keras \n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Conv1D, Dropout,MaxPooling1D,MaxPool1D\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2n5mULxEK_I"
      },
      "source": [
        "<h3>Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAH7TQqmRekp"
      },
      "source": [
        "X_=loadmat('input.mat')\n",
        "X_=pd.DataFrame(X_[\"x\"])\n",
        "X_=(np.asarray(X_)).T\n",
        "\n",
        "Y_=loadmat('class_label.mat')\n",
        "datay=np.asarray(Y_[\"y\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJq-n_cbEOBI"
      },
      "source": [
        "<h3>Initialising datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U58_7LfASaHX"
      },
      "source": [
        "X=[]\n",
        "for i in range(len(X_)):\n",
        "  X.append(X_[i][0])\n",
        "X=np.asarray(X)\n",
        "X=X.transpose(0,2,1)\n",
        "for i in range(len(X)):\n",
        "  X[i]=preprocessing.normalize(X[i])\n",
        "\n",
        "y=[]\n",
        "for i in range(len(datay)):\n",
        "  y.append(datay[i][0]-1)\n",
        "y=np.asarray(y)\n",
        "\n",
        "train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=2/10,train_size=8/10,random_state=0)\n",
        "train_X,valid_X,train_y,valid_y=train_test_split(train_X,train_y,test_size=1/8,train_size=7/8,random_state=0)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-flAmpJEUKx"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19XkV6u5RzUK",
        "outputId": "b468fcb2-0dda-4b8e-b685-5565113471e0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(kernel_size=7, filters=20, input_shape=(800,12)))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(kernel_size=7,filters=60))\n",
        "model.add(MaxPooling1D(pool_size=3,strides=3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=120,kernel_size=7))\n",
        "model.add(Conv1D(filters=120,kernel_size=7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2000,activation=\"relu\"))\n",
        "model.add(Dense(700))\n",
        "model.add(Dense(50))\n",
        "model.add(Dense(7,activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history=model.fit(train_X, train_y, epochs=10, batch_size=1000,validation_data=(valid_X,valid_y),)\n",
        "print(history)\n",
        "loss, acc = model.evaluate(test_X,test_y)\n",
        "# model.metrics_names"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 1.6340 - accuracy: 0.3446 - val_loss: 1.0340 - val_accuracy: 0.4184\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7583 - accuracy: 0.5950 - val_loss: 0.3942 - val_accuracy: 0.8106\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.2300 - accuracy: 0.8964 - val_loss: 0.0447 - val_accuracy: 0.9837\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 1.5767e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.2462e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.0470e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 2.1525e-04 - accuracy: 1.0000 - val_loss: 1.8884e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 3.0602e-04 - accuracy: 0.9999 - val_loss: 1.6234e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 1.9368e-04 - accuracy: 0.9999 - val_loss: 1.3750e-05 - val_accuracy: 1.0000\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7fc8c63bc7b8>\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.6051e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNBg1ToDEdhj"
      },
      "source": [
        "<h3>Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXMBnkNWKren",
        "outputId": "bb8662a3-f39b-4979-c958-f556b910693f"
      },
      "source": [
        "loss, acc = model.evaluate(test_X,test_y)\n",
        "print(f'Accuarcy: {acc*100}%')\n",
        "print(f'Loss: {loss}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 0s 4ms/step - loss: 1.6051e-05 - accuracy: 1.0000\n",
            "Accuarcy: 100.0%\n",
            "Loss: 1.6050786143750884e-05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}