{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Param-Bhatt/NNFL-Assignment/blob/master/2/Q5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qcP6dso9Vfw"
      },
      "source": [
        "<h3>Ignore warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngIvFf9vVach"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b_1AVQV9ZJw"
      },
      "source": [
        "<h3>Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHEW0Kbw8vk-",
        "outputId": "1c600369-11ac-4fd0-ea3a-d30f295cde23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tPvKWLW-gdk"
      },
      "source": [
        "<h3>Navigating to respective directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXGRa0cdLLZS",
        "outputId": "295933c1-b36b-486e-952a-1ded6042058b"
      },
      "source": [
        "%cd \"/content/drive/My Drive/NNFL-Assignments/2\"\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NNFL-Assignments/2\n",
            "assignment2.gdoc  class2_images    class_label.mat  data5.mat\t  input.mat\n",
            "assignment2.pdf   class3_images    data55.xlsx\t    input_a2.mat  label.mat\n",
            "class1_images\t  class_label.csv  data5.csv\t    input.gsheet  Q8.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu1bwdk0-jUJ"
      },
      "source": [
        "<h3>Importing all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDdt4QF3KiDG"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import normalize\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix as cm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryu-jUJ1-mU5"
      },
      "source": [
        "<h3>Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyS9AvMsLHMb"
      },
      "source": [
        "f = loadmat('data5.mat')\n",
        "D = f['x']\n",
        "np.random.shuffle(D)\n",
        "\n",
        "\n",
        "def init_data(data):\n",
        "    X = np.array(data[ : , :-1], dtype = float)\n",
        "    y = np.array(data[ : , -1], dtype = int)\n",
        "    X = (X - X.mean(axis = 0))/X.std(axis = 0)\n",
        "    return X, y\n",
        "\n",
        "X, y = init_data(D)\n",
        "X_train, y_train = X[ :int(0.7 * len(X))], y[ :int(0.7 * len(X))]\n",
        "X_val, y_val = X[ int(0.7 * len(X)): ], y[ int(0.7 * len(X)): ]\n",
        "\n",
        "alpha = 0.1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPpJxGfeLcyk"
      },
      "source": [
        "#sigmoid function\n",
        "def sigmoid(x, derivative=False):\n",
        "        if (derivative == True):\n",
        "            return x * (1 - x)\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZpIvwov-0uf"
      },
      "source": [
        "<h3>The neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIJZyQmnOm0r"
      },
      "source": [
        "class NeuralNetwork(object):\n",
        "    def __init__(self, sizes):\n",
        "        \n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.W = {}\n",
        "        self.a = {}\n",
        "        self.b = {}\n",
        "        \n",
        "        #Initialize Weights\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.W[i] = np.random.randn(self.sizes[i-1], self.sizes[i])\n",
        "            \n",
        "        #Initialize biases\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.b[i] = np.random.randn(self.sizes[i], 1)\n",
        "        \n",
        "        #Initialize activations\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = np.zeros([self.sizes[i], 1])\n",
        "        \n",
        "    #Forward pass\n",
        "    def forward_pass(self, X):\n",
        "        \n",
        "        self.a[0] = X\n",
        "        \n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = sigmoid(np.dot(self.W[i].T, self.a[i-1]) + self.b[i])\n",
        "\n",
        "        return self.a[self.num_layers-1] \n",
        "    \n",
        "    #Backward pass/ Weight Update\n",
        "    def backward_pass(self, X, Y, output):\n",
        "        \n",
        "        self.d = {}\n",
        "        self.d_output = (Y - output) * sigmoid(output, derivative=True)\n",
        "        self.d[self.num_layers-1] = self.d_output\n",
        "        \n",
        "        #Derivatives of the layers\n",
        "        for i in range(self.num_layers-1, 1, -1):\n",
        "            self.d[i-1] = np.dot(self.W[i], self.d[i]) * sigmoid(self.a[i-1], derivative=True)\n",
        "        \n",
        "        #Updating weights\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.W[i] += alpha * np.dot(self.a[i-1], self.d[i].T)\n",
        "            \n",
        "        #Updating biases\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.b[i] += alpha * self.d[i]\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        X = np.reshape(X, (len(X), 1))\n",
        "        output = self.forward_pass(X)\n",
        "        self.backward_pass(X, Y, output)\n",
        "    \n",
        "    def get_W(self):\n",
        "        return self.W\n",
        "    \n",
        "    def load_W(self, W):\n",
        "        self.W = W\n",
        "    \n",
        "    def get_a(self, x):\n",
        "        x = np.reshape(x, (len(x), 1))\n",
        "        self.forward_pass(x)\n",
        "        return self.a\n",
        "    \n",
        "    def load_a(self, a):\n",
        "        self.a = a"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rUc_fl4V0c-"
      },
      "source": [
        "#Cost function\n",
        "def calc_cost(NN,x ,y):\n",
        "    \n",
        "    cost = 0\n",
        "    for i in range(len(x)):\n",
        "        x_ = np.reshape(x[i], (len(x[i]), 1))\n",
        "        cost += 0.5 / len(x) * np.sum((y[i] - NN.forward_pass(x_)) ** 2)\n",
        "    \n",
        "    return cost\n",
        "\n",
        "#Network initialization\n",
        "autoencoder1 = NeuralNetwork([72, 60, 72])\n",
        "autoencoder2 = NeuralNetwork([60,40,60])\n",
        "autoencoder3 = NeuralNetwork([40, 30, 40])\n",
        "NN = NeuralNetwork([72,60,40,30, 1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZkmyCpC_FGR"
      },
      "source": [
        "<h3>Pre-Training our Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGSGsaPUV5j0",
        "outputId": "9586cda4-41c1-498f-ead1-8fe8aba3254b"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Autoencoder 1 pretraining\n",
        "print(\"Autoencoder 1\")\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(X_train):\n",
        "        row = np.reshape(row, (72,1))\n",
        "        autoencoder1.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder1, X_train, X_train)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch: {i+1}, Cost: {cost}\")\n",
        "    \n",
        "#Scores computation for autoencoder 1\n",
        "autoencoder2_input = []\n",
        "\n",
        "for row in X_train:\n",
        "    autoencoder2_input.append(autoencoder1.get_a(row)[1])\n",
        "\n",
        "autoencoder2_input = np.array(autoencoder2_input)\n",
        "\n",
        "\n",
        "#Autoencoder 2 pretraining\n",
        "print(\"Autoencoder 2\")\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(autoencoder2_input):\n",
        "        row = np.reshape(row, (60,1))\n",
        "        autoencoder2.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder2, autoencoder2_input, autoencoder2_input)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch: {i+1}, Cost: {cost}\")\n",
        "\n",
        "\n",
        "#Scores computation for autoencoder 2\n",
        "autoencoder3_input = []\n",
        "\n",
        "for row in autoencoder2_input:\n",
        "    autoencoder3_input.append(autoencoder2.get_a(row)[1])\n",
        "\n",
        "autoencoder3_input = np.array(autoencoder3_input)\n",
        "\n",
        "#Autoencoder 3 pretraining\n",
        "print(\"Autoencoder 3\")\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(autoencoder3_input):\n",
        "        row = np.reshape(row, (40,1))\n",
        "        autoencoder3.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder3, autoencoder3_input, autoencoder3_input)\n",
        "    if (1+i)%100 == 0:\n",
        "        print(f\"Epoch: {i+1}, Cost: {cost}\")\n",
        "\n",
        "#Final network weight initialization\n",
        "W1 = autoencoder1.get_W()[1]\n",
        "W2 = autoencoder2.get_W()[1]\n",
        "W3 = autoencoder3.get_W()[1]\n",
        "W_final = {}\n",
        "W_final[1] = W1\n",
        "W_final[2] = W2\n",
        "W_final[3] = W3\n",
        "W_final[4] = np.random.randn(30, 1)\n",
        "NN.load_W(W_final)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder 1\n",
            "Epoch: 100, Cost: 3130.9104742570507\n",
            "Epoch: 200, Cost: 3133.7368325335938\n",
            "Autoencoder 2\n",
            "Epoch: 100, Cost: 5.075120299884116\n",
            "Epoch: 200, Cost: 5.04923884717336\n",
            "Autoencoder 3\n",
            "Epoch: 100, Cost: 2.734942041969874\n",
            "Epoch: 200, Cost: 2.728714222053555\n",
            "CPU times: user 1min 11s, sys: 28.9 ms, total: 1min 11s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_izJ38-9Cc"
      },
      "source": [
        "<h3>Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQwa-BfpOipi",
        "outputId": "a2c38be8-40a9-48ad-b52d-f8708c38827c"
      },
      "source": [
        "%%time\n",
        "\n",
        "for i in range(500):\n",
        "    if (i+1)%100==0:\n",
        "        print(\"Epoch: \", i+1)\n",
        "\n",
        "    for j in range(len(X_train)):\n",
        "        NN.train(X_train[j], y_train[j])\n",
        "\n",
        "y_pred = []\n",
        "for i in range(len(X_val)):\n",
        "\n",
        "    x = np.reshape(X_val[i], (len(X_val[i]), 1))\n",
        "    x = NN.forward_pass(x)\n",
        "    p = 0 if x[0] < 0.5 else 1\n",
        "    y_pred.append(p)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  100\n",
            "Epoch:  200\n",
            "Epoch:  300\n",
            "Epoch:  400\n",
            "Epoch:  500\n",
            "CPU times: user 1min 12s, sys: 23.3 ms, total: 1min 12s\n",
            "Wall time: 1min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBEUGKND_AWg"
      },
      "source": [
        "<h3>Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNcqQk-iqqao",
        "outputId": "2bfcd925-0ed3-4cf3-a0f3-599bc8f7e9d5"
      },
      "source": [
        "confmat = cm(y_val, y_pred)\n",
        "\n",
        "Accuracy = (confmat[0][0]+confmat[1][1])/len(y_pred)\n",
        "Sensitivity = (confmat[1][1])/(confmat[1][0] + confmat[1][1])\n",
        "Specificity = (confmat[0][0])/(confmat[0][0] + confmat[0][1])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confmat)\n",
        "print(\"\\n\")\n",
        "print(f\"Accuracy: {Accuracy*100}%\\nSensitivity: {Sensitivity}\\nSpecificity: {Specificity}\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[318  16]\n",
            " [ 10 301]]\n",
            "\n",
            "\n",
            "Accuracy: 95.96899224806201%\n",
            "Sensitivity: 0.9678456591639871\n",
            "Specificity: 0.9520958083832335\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}