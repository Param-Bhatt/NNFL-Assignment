{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Param-Bhatt/NNFL-Assignment/blob/master/2/Q7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqYnFcgWBHZ0"
      },
      "source": [
        "<h3>Ignore warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATa7QxW8W4CO"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snt5zOMmBJbY"
      },
      "source": [
        "<h3>Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-Gpz8uBFnC",
        "outputId": "87aae5b5-e7a4-48dc-d91a-f14dc44efa03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hsneY2GBLXY"
      },
      "source": [
        "<h3>Navigating to respective directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0cJLxNsSxCk",
        "outputId": "0684a2a4-4857-4330-dfb4-b600c473f4ba"
      },
      "source": [
        "%cd \"/content/drive/My Drive/NNFL-Assignments/2\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NNFL-Assignments/2\n",
            "assignment2.gdoc  class2_images    class_label.mat  data5.mat\t  input.mat\n",
            "assignment2.pdf   class3_images    data55.xlsx\t    input_a2.mat  label.mat\n",
            "class1_images\t  class_label.csv  data5.csv\t    input.gsheet  Q8.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5ZlWwcuBONG"
      },
      "source": [
        "<h3>Importing all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYiWkY2A8AQS"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import normalize\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN0CimHBBQdj"
      },
      "source": [
        "<h3>Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chq_amaN5ye"
      },
      "source": [
        "mat_contents = loadmat('data5.mat')\n",
        "data = mat_contents['x']\n",
        "np.random.shuffle(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVlbQbtPBVRz"
      },
      "source": [
        "<h3>Initialize data, sanitize if required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOd82655OiNe"
      },
      "source": [
        "def init_data():\n",
        "    X = np.array(data[ : , :-1], dtype = float)\n",
        "    y = np.array(data[ : , -1], dtype = int)\n",
        "    X = normalize(X, axis = 0)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X, y_ = init_data()\n",
        "y = np.zeros((len(y_), 2))\n",
        "for i in range(len(y_)):\n",
        "    if y_[i]==1:\n",
        "        y[i,1] = 1.0\n",
        "    elif y_[i]==0:\n",
        "        y[i,0] = 1.0\n",
        "\n",
        "\n",
        "X_train, y_train = X[ :int(0.7 * len(X))], y[ :int(0.7 * len(X))]\n",
        "X_val, y_val = X[ int(0.7 * len(X)): ], y[ int(0.7 * len(X)): ]\n",
        "\n",
        "alpha = 0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDXv7LoHOkCe"
      },
      "source": [
        "#Sigmoid function\n",
        "def sigmoid(x, derivative=False):\n",
        "        if (derivative == True):\n",
        "            return x * (1 - x)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#Tanh function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "#Cost function\n",
        "def calc_cost(NN,x ,y):\n",
        "    \n",
        "    cost = 0\n",
        "    for i in range(len(x)):\n",
        "        x_ = np.reshape(x[i], (len(x[i]), 1))\n",
        "        cost += 0.5 / len(x) * np.sum((y[i] - NN.forward_pass(x_)) ** 2)\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykPPHCxNBbMr"
      },
      "source": [
        "<h3>The neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYaPZOd6SqVa"
      },
      "source": [
        "#Neural network class\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self, sizes):\n",
        "        \n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.W = {}\n",
        "        self.a = {}\n",
        "        self.b = {}\n",
        "        \n",
        "        #Initialize Weights\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.W[i] = np.random.randn(self.sizes[i-1], self.sizes[i])\n",
        "            \n",
        "        #Initialize biases\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.b[i] = np.random.randn(self.sizes[i], 1)\n",
        "        \n",
        "        #Initialize activations\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = np.zeros([self.sizes[i], 1])\n",
        "        \n",
        "    #Forward pass to compute scores\n",
        "    def forward_pass(self, X):\n",
        "        \n",
        "        self.a[0] = X\n",
        "        \n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = sigmoid(np.dot(self.W[i].T, self.a[i-1]) + self.b[i])\n",
        "\n",
        "        return self.a[self.num_layers-1] \n",
        "    \n",
        "    #Backward pass to update weights\n",
        "    def backward_pass(self, X, Y, output):\n",
        "        \n",
        "        self.d = {}\n",
        "        self.d_output = (Y - output) * sigmoid(output, derivative=True)\n",
        "        self.d[self.num_layers-1] = self.d_output\n",
        "        \n",
        "        #Derivatives of the layers\n",
        "        for i in range(self.num_layers-1, 1, -1):\n",
        "            self.d[i-1] = np.dot(self.W[i], self.d[i]) * sigmoid(self.a[i-1], derivative=True)\n",
        "        \n",
        "        #Updating weights\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.W[i] += alpha * np.dot(self.a[i-1], self.d[i].T)\n",
        "            \n",
        "        #Updating biases\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.b[i] += alpha * self.d[i]\n",
        "\n",
        "    #Training helper function   \n",
        "    def train(self, X, Y):\n",
        "        X = np.reshape(X, (len(X), 1))\n",
        "        output = self.forward_pass(X)\n",
        "        self.backward_pass(X, Y, output)\n",
        "\n",
        "    #Get weights    \n",
        "    def get_W(self):\n",
        "        return self.W\n",
        "    \n",
        "    #Load specified weights\n",
        "    def load_W(self, W):\n",
        "        self.W = W\n",
        "\n",
        "    #Scores computation for given input    \n",
        "    def get_a(self, x):\n",
        "        x = np.reshape(x, (len(x), 1))\n",
        "        self.forward_pass(x)\n",
        "        return self.a\n",
        "    \n",
        "    #Helper function for autoencoder chaining\n",
        "    def load_a(self, a):\n",
        "        self.a = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bJKgOV3BlPj"
      },
      "source": [
        "<h3>Pre training our auto encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9uKbhbzCRs4",
        "outputId": "6eb27047-45c7-4747-e9de-a4b40b747d83"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Initialization\n",
        "autoencoder1 = NeuralNetwork([72, 60, 72])\n",
        "autoencoder2 = NeuralNetwork([60,40,60])\n",
        "print(\"Autoencoder 1 Pre-Training\")\n",
        "#Autoencoder 1 pre-training\n",
        "for i in range(500):\n",
        "    for j, row in enumerate(X_train):\n",
        "        row = np.reshape(row, (72,1))\n",
        "        autoencoder1.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder1, X_train, X_train)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch {i+1}, Cost {cost}\")\n",
        "    \n",
        "autoencoder2_input = []\n",
        "\n",
        "for row in X_train:\n",
        "    autoencoder2_input.append(autoencoder1.get_a(row)[1])\n",
        "\n",
        "autoencoder2_input = np.array(autoencoder2_input)\n",
        "print(\"===========================\")\n",
        "print(\"Autoencoder 2 Pre-Training\")\n",
        "#Autoencoder 2 pre-training\n",
        "for i in range(500):\n",
        "    for j, row in enumerate(autoencoder2_input):\n",
        "        row = np.reshape(row, (60,1))\n",
        "        autoencoder2.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder2, autoencoder2_input, autoencoder2_input)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch {i+1}, Cost {cost}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder 1 Pre-Training\n",
            "Epoch 100, Cost 372.07591811089117\n",
            "Epoch 200, Cost 372.06021344494155\n",
            "Epoch 300, Cost 372.0583086151749\n",
            "Epoch 400, Cost 372.0590774566716\n",
            "Epoch 500, Cost 372.0604495920463\n",
            "===========================\n",
            "Autoencoder 2 Pre-Training\n",
            "Epoch 100, Cost 5.760825013875956\n",
            "Epoch 200, Cost 5.760688361867541\n",
            "Epoch 300, Cost 5.760625752786266\n",
            "Epoch 400, Cost 5.7605861055944985\n",
            "Epoch 500, Cost 5.760562433842133\n",
            "CPU times: user 2min 7s, sys: 93 ms, total: 2min 7s\n",
            "Wall time: 2min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWeTH691B_O-"
      },
      "source": [
        "<h3>Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3A3_N_FCUku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee75635-cbec-4ef7-d9f5-72ae48c86fa3"
      },
      "source": [
        "%%time\n",
        "\n",
        "#ELM Input\n",
        "elm_input = []\n",
        "for row in autoencoder2_input:\n",
        "    elm_input.append(autoencoder2.get_a(row)[1])   \n",
        "elm_input = np.array(elm_input)\n",
        "\n",
        "#ELM Params\n",
        "elm_neurons = 550\n",
        "output_neurons = 2\n",
        "W_elm = np.random.randn(elm_input.shape[1], elm_neurons)\n",
        "\n",
        "#ELM Training\n",
        "np.random.seed(1)\n",
        "elm_input = np.reshape(elm_input, (1503, 40))\n",
        "H = np.matmul(elm_input, W_elm)\n",
        "H = tanh(H)\n",
        "H_inv = np.linalg.pinv(H)\n",
        "W_final = np.matmul(H_inv, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 530 ms, sys: 122 ms, total: 652 ms\n",
            "Wall time: 347 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAmX4HqzCB5n"
      },
      "source": [
        "<h3>Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCKVTckCaxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eddc944-0dcf-4098-f3f8-54a8ec05be2a"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Autoencoder 1 forward pass\n",
        "layer1_out = []\n",
        "\n",
        "for i, row in enumerate(X_val):\n",
        "    act = autoencoder1.get_a(row)[1]\n",
        "    layer1_out.append(act)\n",
        "    \n",
        "layer1_out = np.array(layer1_out)\n",
        "layer1_out = np.reshape(layer1_out, (645, 60))\n",
        "\n",
        "#Autoencoder 2 forward pass\n",
        "layer2_out = []\n",
        "\n",
        "for i, row in enumerate(layer1_out):\n",
        "    act = autoencoder2.get_a(row)[1]\n",
        "    layer2_out.append(act)\n",
        "    \n",
        "layer2_out = np.array(layer2_out)\n",
        "layer2_out = np.reshape(layer2_out, (645, 40))\n",
        "\n",
        "#ELM forward pass\n",
        "H_T = np.matmul(layer2_out, W_elm)\n",
        "H_T = tanh(H_T)\n",
        "y_pred = np.matmul(H_T, W_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 77.3 ms, sys: 52.5 ms, total: 130 ms\n",
            "Wall time: 65.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9KNnzTNBgPI"
      },
      "source": [
        "<h3>Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj-UVANlB3Ve",
        "outputId": "22760c8f-d8c5-4974-bd7f-b79635b9baa5"
      },
      "source": [
        "a = [np.argmax(y_pred[i]) for i in range(len(y_pred))]\n",
        "b = [np.argmax(y_val[i]) for i in range(len(y_val))]\n",
        "\n",
        "confmat = cm(b,a)\n",
        "Accuracy = (confmat[0][0]+confmat[1][1])/len(y_pred)\n",
        "Sensitivity = (confmat[1][1])/(confmat[1][0] + confmat[1][1])\n",
        "Specificity = (confmat[0][0])/(confmat[0][0] + confmat[0][1])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confmat)\n",
        "print(\"\\n\")\n",
        "print(f\"Accuracy: {Accuracy*100}%\\nSensitivity: {Sensitivity}\\nSpecificity: {Specificity}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[277  58]\n",
            " [ 45 285]]\n",
            "\n",
            "\n",
            "Accuracy: 87.13178294573643%\n",
            "Sensitivity: 0.8636363636363636\n",
            "Specificity: 0.826865671641791\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSIEKiAxR8r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}